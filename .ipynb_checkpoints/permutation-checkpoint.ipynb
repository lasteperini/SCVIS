{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorial sklearn \n",
    "\n",
    "link https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py\n",
    "\n",
    "In questo esempio, calcoliamo l'importanza della permutazione sul set di dati del cancro al seno del Wisconsin utilizzando permutation_importance. RandomForestClassifier può facilmente ottenere una precisione di circa il 97% su un set di dati di test. Poiché questo set di dati contiene caratteristiche multicollineari, l'importanza della permutazione mostrerà che nessuna delle caratteristiche è importante. Un approccio alla gestione della multicollinearità consiste nell'eseguire il raggruppamento gerarchico sulle correlazioni di ordine di classificazione di Spearman delle caratteristiche, selezionare una soglia e mantenere una singola caratteristica da ciascun cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innanzitutto, addestriamo una foresta casuale sul set di dati del cancro al seno e ne valutiamo l'accuratezza su un set di test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Accuracy on test data: {:.2f}\".format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grafico dell'importanza della permutazione mostra che la permutazione di una caratteristica riduce la precisione al massimo di 0,012, il che suggerisce che nessuna delle caratteristiche è importante. Ciò è in contraddizione con l'elevata accuratezza del test calcolata sopra: alcune caratteristiche devono essere importanti. L'importanza della permutazione viene calcolata sul set di addestramento per mostrare quanto il modello si basi su ciascuna caratteristica durante il training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(clf, X_train, y_train, n_repeats=10,\n",
    "                                random_state=42)\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "tree_importance_sorted_idx = np.argsort(clf.feature_importances_)\n",
    "tree_indices = np.arange(0, len(clf.feature_importances_)) + 0.5\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ax1.barh(tree_indices,\n",
    "         clf.feature_importances_[tree_importance_sorted_idx], height=0.7)\n",
    "ax1.set_yticks(tree_indices)\n",
    "ax1.set_yticklabels(data.feature_names[tree_importance_sorted_idx])\n",
    "ax1.set_ylim((0, len(clf.feature_importances_)))\n",
    "ax2.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n",
    "            labels=data.feature_names[perm_sorted_idx])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando le caratteristiche sono allineate, la permutazione di una caratteristica avrà scarso effetto sulle prestazioni dei modelli perché può ottenere le stesse informazioni da una caratteristica correlata. Un modo per gestire le funzionalità multicollineari è eseguire il clustering gerarchico sulle correlazioni di ordine di classificazione di Spearman, selezionare una soglia e mantenere una singola funzionalità da ciascun cluster. Per prima cosa, tracciamo una mappa termica delle caratteristiche correlate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "corr = spearmanr(X).correlation\n",
    "corr_linkage = hierarchy.ward(corr)\n",
    "dendro = hierarchy.dendrogram(\n",
    "    corr_linkage, labels=data.feature_names.tolist(), ax=ax1, leaf_rotation=90\n",
    ")\n",
    "dendro_idx = np.arange(0, len(dendro['ivl']))\n",
    "\n",
    "ax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro['ivl'], rotation='vertical')\n",
    "ax2.set_yticklabels(dendro['ivl'])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successivamente, selezioniamo manualmente una soglia mediante ispezione visiva del dendrogramma per raggruppare le nostre caratteristiche in cluster e scegliamo una caratteristica da ogni cluster da mantenere, selezioniamo quelle caratteristiche dal nostro set di dati e addestriamo una nuova foresta casuale. L'accuratezza del test della nuova foresta casuale non è cambiata molto rispetto alla foresta casuale addestrata sul set di dati completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = hierarchy.fcluster(corr_linkage, 1, criterion='distance')\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "\n",
    "X_train_sel = X_train[:, selected_features]\n",
    "X_test_sel = X_test[:, selected_features]\n",
    "\n",
    "clf_sel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_sel.fit(X_train_sel, y_train)\n",
    "print(\"Accuracy on test data with features removed: {:.2f}\".format(\n",
    "      clf_sel.score(X_test_sel, y_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
